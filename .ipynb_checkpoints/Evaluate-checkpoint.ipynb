{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9af0dd74-3a26-428c-9dd0-470e1f04b205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytorch_grad_cam\n",
    "import pickle\n",
    "import json\n",
    "import json\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from metric import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b862ff0-b323-4d05-aad2-76e633fe6b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_RGB(img_path):\n",
    "    img = cv2.cvtColor(cv2.imread(img_path, cv2.IMREAD_UNCHANGED),cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "def load_gray(img_path):\n",
    "    return cv2.imread(img_path,cv2.IMREAD_UNCHANGED)\n",
    "def get_images(dataset, video_index, image_index):\n",
    "    \n",
    "    video_name = str(video_index)\n",
    "    if video_index <= 9:\n",
    "        video_name = \"0\" + str(video_index)\n",
    "    video_directory = os.path.join(dataset,video_name)\n",
    "    image_directory = os.path.join(video_directory, str(image_index))\n",
    "    mask = 255 * np.load(os.path.join(image_directory,\"mask.npy\"),allow_pickle = True)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    final = load_RGB(os.path.join(image_directory,\"final.jpg\"))\n",
    "    box = load_RGB(os.path.join(image_directory,\"box.jpg\"))\n",
    "    garmin_directory = os.path.join(video_directory, \"garmin\")\n",
    "    saliency_directory = os.path.join(video_directory, \"saliency\")\n",
    "    #print(dataset, video_directory, image_directory, garmin_directory, saliency_directory)\n",
    "    garmin_image = load_RGB(os.path.join(garmin_directory,str(image_index) + \".jpg\"))\n",
    "    saliency_image = cv2.cvtColor(cv2.imread(os.path.join(saliency_directory,str(image_index) + \".jpg\"),cv2.IMREAD_UNCHANGED),cv2.COLOR_BGR2GRAY)\n",
    "    #print(saliency_image.shape)\n",
    "    #print(mask.shape)\n",
    "    #print(mask.min(),mask.max())\n",
    "    #mask = mask / mask.max()\n",
    "    #print(mask.dtype)\n",
    "    #mask = mask.astype(np.float32)\n",
    "    #mask = saliency_image.astype(np.float32) / 255\n",
    "    #mask = saliency_image.astype(np.float32)\n",
    "    #print(saliency_image.max(),saliency_image.min())\n",
    "    return final,box,mask,garmin_image,saliency_image\n",
    "def show_images(images):\n",
    "    d = len(images) // 2\n",
    "    if len(images) % 2 == 1:\n",
    "        d += 1\n",
    "    fig = plt.figure(figsize = (40,40))\n",
    "    cnt = 1\n",
    "    for i in range(len(images)):\n",
    "        #print(d,2,cnt)\n",
    "        \n",
    "        fig.add_subplot(d,2,cnt)\n",
    "        cnt += 1\n",
    "        img = images[i]\n",
    "        print(img.shape)\n",
    "        print(img.max(),img.min())\n",
    "        if len(img.shape) == 2:\n",
    "            plt.imshow(img,cmap = 'gray')\n",
    "        else:\n",
    "            plt.imshow(img)\n",
    "            \n",
    "def combine_images(images):\n",
    "    new_images = []\n",
    "    for im in images:\n",
    "        print(im.max(),im.min(),im.dtype)\n",
    "        if im.shape[0] == 540:\n",
    "            new_im = cv2.resize(im,dsize = None,fx = 0.5, fy = 0.5)\n",
    "            new_images.append(new_im)\n",
    "        else:\n",
    "            new_images.append(im)\n",
    "    final_image = np.zeros((new_images[0].shape[0],5 * new_images[0].shape[1] + 250,3),dtype = np.uint8)\n",
    "    final_image += 255\n",
    "    cnt = 0\n",
    "    (l,b) = new_images[0].shape[0], new_images[0].shape[1]\n",
    "    for im in new_images:\n",
    "        if len(im.shape) == 2:\n",
    "            im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "        final_image[0:l,cnt * (b + 50) : (cnt + 1) * b + cnt * 50,:] = im\n",
    "        cnt += 1\n",
    "    return final_image\n",
    "        \n",
    "    \n",
    "            \n",
    "def generate_image(video_index,img_index):\n",
    "    dataset_directory = \"./../DREYEVE_DATA_OUTPUT/\"\n",
    "    final,box,mask,garmin_image,saliency_image = get_images(dataset_directory,video_index,img_index)\n",
    "    final_image = combine_images([final,box,mask,garmin_image,saliency_image])\n",
    "    #plt.imshow(final_image)\n",
    "    return final_image\n",
    "    \n",
    "def save_RGB(path,img):\n",
    "    cv2.imwrite(path,cv2.cvtColor(img,cv2.COLOR_RGB2BGR))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8bf8956-6e0d-4b25-ba01-b804b5880d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#each video folder has info data file \n",
    "#data file is indexed with image index for example {0 : obj, 5 : obj , 10 : obj}\n",
    "#each obj has index and size, if size = 0, then it is empty, otherwise we have it has obj['objects'] where object[3] = contains details of each obhect\n",
    "dataset_path = \"./../DREYEVE_DATA_OUTPUT\"\n",
    "def generate_all_relevant_image_paths(video_index):\n",
    "    video_name = str(video_index)\n",
    "    if video_index < 10:\n",
    "        video_name = \"0\" + video_name\n",
    "    paths = []\n",
    "    video_path = os.path.join(dataset_path, video_name)\n",
    "    dict_path = os.path.join(video_path,\"info_data.json\")\n",
    "    #print(dict_path)\n",
    "    f = open(dict_path,\"r\")\n",
    "    data = json.load(f)\n",
    "    for index in data.keys():\n",
    "        if data[index][\"size\"] > 0:\n",
    "            mask_path = os.path.join(os.path.join(video_path,index),\"mask.npy\")\n",
    "            gt_path = os.path.join(os.path.join(video_path,\"saliency\"),str(index) + \".jpg\")\n",
    "            paths.append([mask_path,gt_path])\n",
    "    return paths\n",
    "\n",
    "def compute_metrics(paths):\n",
    "    similarity = 0\n",
    "    cnt = 0 \n",
    "    for path in paths:\n",
    "        mask_path = path[0]\n",
    "        gt_path = path[1]\n",
    "        mask = np.load(mask_path,allow_pickle = True)\n",
    "        gt = cv2.imread(gt_path,cv2.IMREAD_UNCHANGED)\n",
    "        #resize to half\n",
    "        gt = cv2.resize(gt, dsize = None , fx = 0.5, fy = 0.5)\n",
    "        #change to correct data format float32\n",
    "        gt = gt.astype(np.float32)\n",
    "        #normalize\n",
    "        gt = gt / 255.0\n",
    "        #convert to grayscale \n",
    "        gt = cv2.cvtColor(gt, cv2.COLOR_BGR2GRAY)\n",
    "        similarity = similarity + cosine_similarity(mask,gt)\n",
    "        cnt += 1\n",
    "    return similarity / (cnt + 0.001)\n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbc7b3c9-b8f8-48bd-b28f-83c4934cdec6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.spatial.distance' has no attribute 'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3902/105591860.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_all_relevant_image_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3902/2311554485.py\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(paths)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#convert to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/saliency/pytorch-grad-cam/metric.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(gt, mask)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmask_flattened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mgt_flattened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_flattened\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt_flattened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize_saliency_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaliency_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcdf_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'scipy.spatial.distance' has no attribute 'c'"
     ]
    }
   ],
   "source": [
    "print(compute_metrics(generate_all_relevant_image_paths(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a7e8f-5968-448d-9db3-41fb725d351f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
